{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiclass Logistic Regression on Cardiotocography dataset for FHR pattern Class code 1 to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"CTG.xls\",\"Raw Data\")\n",
    "data = data[1:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing dataset into train and test set 75% data into training set, rest into test set\n",
    "ind = np.random.rand(len(data)) < 0.75\n",
    "train = data[ind]\n",
    "test = data[~ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set is 1645\n"
     ]
    }
   ],
   "source": [
    "# Train set   also the classes are available in one hot form already in dataset(Given in Description sheet of dataset)\n",
    "X = train[['LBE','LB','AC','FM','UC','ASTV','MSTV','ALTV','MLTV','DL','DS','DP','Width','Min','Max','Nmax','Nzeros','Mode','Mean','Median','Variance','Tendency']]\n",
    "Y = train[['A','B','C','D','E','AD','DE','LD','FS','SUSP']]\n",
    "Y_class = Y.to_numpy()\n",
    "X = X.to_numpy()\n",
    "print(\"Size of training set is\",len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of test set is 481\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "Xt = test[['LBE','LB','AC','FM','UC','ASTV','MSTV','ALTV','MLTV','DL','DS','DP','Width','Min','Max','Nmax','Nzeros','Mode','Mean','Median','Variance','Tendency']]\n",
    "Yt = test[['A','B','C','D','E','AD','DE','LD','FS','SUSP']]\n",
    "Yt_class = Yt.to_numpy()\n",
    "Xt = Xt.to_numpy()\n",
    "print(\"Size of test set is\",len(Yt_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding ones column on training set data\n",
    "ones = np.asmatrix(np.ones(len(X))).T\n",
    "X = np.hstack((ones,X))\n",
    "N = len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization of training set\n",
    "for i in range(1,23):\n",
    "    X[:,i] = (X[:,i] - np.mean(X[:,i]))/np.std(X[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate (W*X)\n",
    "def W_x_X(X, W):\n",
    "    return (X.dot(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax function, substracted by max to remove nan values\n",
    "def softmax(a):\n",
    "    a_max = np.max(a, axis=-1)\n",
    "    exp_a = np.exp(a - a_max)\n",
    "    return exp_a / np.sum(exp_a, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For labelling on predicton, gives one to maximum probability column\n",
    "def classlabel(z):\n",
    "    return z.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Entropy Function\n",
    "def crossEntropy(y_pred, y):\n",
    "    return - np.sum(np.multiply(np.log(y_pred),(y)),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates Cost\n",
    "def cost(y_pred,y):\n",
    "    return np.mean(crossEntropy(y_pred,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates Gradient of Cost\n",
    "def gradCost(y_pred,y,X):\n",
    "    return X.T @ (y_pred - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Weight Matrix of size (p,k)   where p = number of features and k = number of classes\n",
    "#W = np.random.random(size=(23,10))\n",
    "W = np.random.randint(-10,10,size=(23,10))\n",
    "#W = np.zeros((23,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = W_x_X(X,W)\n",
    "y_pred = softmax(inp)\n",
    "crossentropy = crossEntropy(y_pred,Y_class)\n",
    "J = cost(y_pred,Y_class)\n",
    "grad = gradCost(y_pred,Y_class,X)\n",
    "W = W - 0.01*(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights after Gradient Descent are \n",
      "\n",
      " [[ 4.41983983e+00  2.14735002e+01 -1.84647975e+00 -1.66415453e+00\n",
      "   2.05711273e+00  2.46231121e+01  1.05876552e+01 -1.10614255e+01\n",
      "  -2.69354225e+01 -2.56537377e+01]\n",
      " [-2.48924909e+00 -6.35684846e+00 -3.01489810e+00 -9.95023106e+00\n",
      "  -9.43695772e+00 -7.77226297e-01  4.90855315e+00  6.49950463e+00\n",
      "   3.43410864e+00  3.18324429e+00]\n",
      " [ 3.51075091e+00  3.64315154e+00  6.98510190e+00 -4.95023106e+00\n",
      "  -4.43695772e+00 -1.77722630e+00 -3.09144685e+00  1.49950463e+00\n",
      "   7.43410864e+00  7.18324429e+00]\n",
      " [-5.99766110e+00  1.12192434e+01 -9.02270810e+00  1.22362325e+01\n",
      "  -9.64379025e+00  1.02119325e+01 -1.55474692e+01  3.17666542e-01\n",
      "   8.84829685e+00 -6.62174312e+00]\n",
      " [-2.66024078e+00 -1.21718161e+00  2.73327776e+00  1.67977245e+00\n",
      "   3.49188752e+00 -1.30365858e+00 -1.62372714e+00 -4.27743198e-01\n",
      "  -4.94198309e+00  5.26959667e+00]\n",
      " [ 1.41763362e+00  1.48999086e-01 -2.82884359e-01  7.73615000e-02\n",
      "   4.69620415e-02  1.81321104e-01 -3.65065832e-01 -7.80105554e-01\n",
      "  -8.17939541e+00 -5.26482620e+00]\n",
      " [-4.35516487e+00 -1.98833506e+00 -4.53809429e+00 -3.85039384e+00\n",
      "   1.20496619e+00 -3.61492478e+00 -5.51858451e+00 -7.31497752e-01\n",
      "   1.81564111e+01  4.23561776e+00]\n",
      " [-3.34304495e+00 -1.64374801e+00 -2.58400173e+00 -1.81814134e+00\n",
      "  -5.26533355e+00 -1.31656458e+00 -3.54717365e+00 -4.44200671e+00\n",
      "   2.66373189e+00 -2.27037174e+01]\n",
      " [ 9.94537789e-01  9.26466774e-01 -2.14682206e+00 -9.00467825e-01\n",
      "   1.61008635e+00 -8.08365447e-01  1.65703771e+00  1.87853057e+00\n",
      "   1.10103805e+01  5.77861562e+00]\n",
      " [-3.35069483e+00 -3.93323550e+00 -4.98038584e-01 -5.63017953e+00\n",
      "  -2.95970742e+00 -4.68878743e+00 -4.25992129e+00  1.89521143e-01\n",
      "  -2.98137895e+00  2.11242240e+00]\n",
      " [-3.03978110e-01 -2.77744502e+00  1.21303430e+00 -1.49961455e+01\n",
      "  -1.12927433e+00  5.94509922e+00  6.47657733e+00  6.69222764e+00\n",
      "  -8.12304750e-02  4.96113494e+00]\n",
      " [-1.07009952e+00 -3.35640599e+00  2.81245040e+00  3.73214134e+00\n",
      "  -3.59527690e+00 -1.46253540e+00 -1.04239848e+01  6.81709694e-01\n",
      "   5.27326043e-01  3.15467514e+00]\n",
      " [-2.72441062e+00 -9.61476906e+00 -6.53937640e+00 -5.70558307e-03\n",
      "  -1.13056533e+01  5.84331365e+00  6.58167282e+00  9.05939993e+00\n",
      "   1.42589734e+01 -2.55344485e+00]\n",
      " [-3.45822317e+00 -7.63072945e+00 -2.12229096e+00 -2.46287467e+00\n",
      "  -3.39823591e+00 -5.09901100e+00  6.56602626e+00 -2.37417197e+00\n",
      "   7.36641849e+00 -1.38690762e+00]\n",
      " [-8.02073560e+00 -5.03368766e+00 -4.61733268e-01 -1.60220946e-01\n",
      "  -5.25465268e+00 -4.97468606e+00  2.44301325e+00 -6.03768619e+00\n",
      "  -2.60976001e+00 -2.88985084e+00]\n",
      " [ 8.20125693e-01  4.38705570e+00 -4.01149005e-01  3.40318223e+00\n",
      "   8.78054370e-01  3.43851218e+00 -2.13703291e+00  3.87474461e+00\n",
      "  -5.83460402e+00  5.71111152e-01]\n",
      " [-2.13386175e+00 -1.95693755e+00  1.40348556e+00 -2.38758838e+00\n",
      "   4.95090727e-01 -2.09564726e+00 -1.96267897e+00 -3.58318368e+00\n",
      "  -1.10950832e+01 -1.68359552e+00]\n",
      " [ 3.32209545e+00  2.43150965e+00  3.09184542e+00  1.48344822e+00\n",
      "   2.22899980e+00  2.80523094e+00  3.32742949e+00  2.61052715e+00\n",
      "  -3.05540776e+00 -1.24567835e+00]\n",
      " [-2.06039000e+00 -5.18975408e+00 -4.08782440e+00 -4.36018027e+00\n",
      "   6.92504595e-01 -1.46343288e+00  3.22210491e-01  3.77248928e+00\n",
      "  -7.44960157e+00  6.82397885e+00]\n",
      " [-1.34926642e+01 -6.21631799e-02 -8.70264493e+00  4.56144778e+00\n",
      "   7.09805158e+00 -1.87623002e-01 -2.76805734e+00 -1.28896910e+01\n",
      "   6.69224405e+00 -1.82488997e+01]\n",
      " [ 6.45149588e+00  4.17212118e+00  2.01938214e+00  1.48130834e+01\n",
      "   1.23224978e+01 -1.74025837e+00 -5.64806887e+00 -1.91690376e+01\n",
      "  -8.46986446e+00  2.24864890e+00]\n",
      " [-1.90730005e+01  8.03526489e+00 -1.36552243e+01  1.07339981e+01\n",
      "   4.83038667e+00  8.83331997e+00  8.94066890e+00  1.31785319e+01\n",
      "   3.52369659e+00 -2.63476422e+01]\n",
      " [-1.05391839e+00  1.69314145e+00  2.57988828e-01  2.85408999e+00\n",
      "  -6.08601475e-01  2.23855688e+00  2.35995358e+00  3.72823434e+00\n",
      "  -3.59328978e+00  1.12384458e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Applying Gradient Descent \n",
    "iterations = 2500\n",
    "alpha = 0.01\n",
    "Jj = []\n",
    "for i in range(iterations):\n",
    "    inp = W_x_X(X,W)\n",
    "    y_pred = softmax(inp)\n",
    "    #print(y_pred,\"\\n\\n\\n\")\n",
    "    crossentropy = crossEntropy(y_pred,Y_class)\n",
    "    J = cost(y_pred,Y_class)\n",
    "    Jj.append(J)\n",
    "    grad = gradCost(y_pred,Y_class,X)\n",
    "    W = W - alpha*(grad)\n",
    "    #print(W,\"\\n\\n\\n\")\n",
    "print(\"The weights after Gradient Descent are \\n\\n\",W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting cost\n",
    "plt.plot(Jj)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting labels of Given dataset between 0-9\n",
    "label_train = classlabel(Y_class)\n",
    "# Getting labels of result from Logistic Regression\n",
    "label_pred = classlabel(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  278  out of  1645 are misclassified giving accuracy of 83.10030395136778  on training set\n"
     ]
    }
   ],
   "source": [
    "# Calculating misclassifications on Training set\n",
    "count = 0\n",
    "for i in range(len(label_train)):\n",
    "    if label_pred[i,0]!=label_train[i]:\n",
    "        count = count + 1\n",
    "        #print(i,\"\\t\",y_pred_classes[i],\"\\t\",Y_class[i])\n",
    "print(\"Total \",count,\" out of \",len(X),\"are misclassified giving accuracy of\",100*((len(X)-count)/len(X)),\" on training set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations on test set\n",
    "# adding ones column\n",
    "ones = np.asmatrix(np.ones(len(Xt))).T\n",
    "Xt = np.hstack((ones,Xt))\n",
    "\n",
    "# Standardization of test set\n",
    "for i in range(1,23):\n",
    "    Xt[:,i] = (Xt[:,i] - np.mean(Xt[:,i]))/np.std(Xt[:,i])\n",
    "\n",
    "\n",
    "inpt = W_x_X(Xt,W)\n",
    "y_pred_t = softmax(inpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting labels of Given dataset between 0-9\n",
    "label_test = classlabel(Yt_class)\n",
    "# Getting labels of result from Logistic Regression\n",
    "label_pred_test = classlabel(y_pred_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total  120  out of  481 are misclassified giving accuracy of 75.05197505197505  on test set\n"
     ]
    }
   ],
   "source": [
    "# Calculating misclassifications on Training set\n",
    "count_t = 0\n",
    "for i in range(len(label_test)):\n",
    "    if label_pred_test[i,0]!=label_test[i]:\n",
    "        count_t = count_t + 1\n",
    "        #print(i,\"\\t\",y_pred_classes[i],\"\\t\",Y_class[i])\n",
    "print(\"Total \",count_t,\" out of \",len(Xt),\"are misclassified giving accuracy of\",100*((len(Xt)-count_t)/len(Xt)),\" on test set\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
